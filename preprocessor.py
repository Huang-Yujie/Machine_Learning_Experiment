import pandas as pd
import jieba

def readFile(file_name):
    fp = open(file_name, "r", encoding="utf-8")
    content_lines = fp.readlines()
    fp.close()
    #å»é™¤è¡Œæœ«çš„æ¢è¡Œç¬¦ï¼Œå¦åˆ™ä¼šåœ¨åœç”¨è¯åŒ¹é…çš„è¿‡ç¨‹ä¸­äº§ç”Ÿå¹²æ‰°
    for i in range(len(content_lines)):
        content_lines[i] = content_lines[i].rstrip("\n")
    return content_lines

def wordCut (lines):
    stopwords = readFile("stopwords.txt")
    userStopwords = ['\t', ' ', ',', '~', '_', '...', 'â€¦', '##', '|', '!', 'ğŸ¤£', 'â¤', 'ğŸ™', '\u200b', 'http', 't', 'cn', 'â˜', 'âŒ', 'â—', 'ã€œ']
    stopwords += userStopwords
    wordLists = []
    for line in lines :
        wordList = []
        wordList += [word for word in jieba.cut(line) if word not in stopwords]
        wordLists.append(' '.join(wordList))
    return wordLists

def preprocess(dataset):
    # dataset = pd.read_csv('train.csv')
    dataset.fillna (' ', inplace = True)
    dataset['text'] = dataset['content'] + dataset['comment_all']
    dataset.drop (dataset.columns[[0, 1, 2]], axis = 1, inplace = True)
    dataset["textCut"] = wordCut(dataset["text"])
    print (dataset)
    return dataset

dataset = pd.read_csv('train.csv')
preprocess(dataset).to_csv ("trainCut.csv")
dataset = pd.read_csv('test.csv')
preprocess(dataset).to_csv ("testCut.csv")